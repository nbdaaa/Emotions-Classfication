{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8449139e-9ab6-4526-964a-dc748b9c9dcf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tiktoken\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4f1c0932-a963-4c2f-85e4-1552f21b8811",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ec867471-a49c-48e3-929b-d874e180bec3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Load the datasets\n",
    "train_data = pd.read_csv('Dataset/Processed dataset/train_data.csv')\n",
    "test_data = pd.read_csv('Dataset/Processed dataset/test_data.csv')\n",
    "val_data = pd.read_csv('Dataset/Processed dataset/validation_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "529d9ba2-be90-4e69-8452-ac9e0e035885",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drop the 'sentiment' column from all datasets\n",
    "train_data = train_data.drop('sentiment', axis=1)\n",
    "test_data = test_data.drop('sentiment', axis=1)\n",
    "val_data = val_data.drop('sentiment', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d6a85937-2dd1-4904-a2ae-7607649792ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape: (161613, 2)\n",
      "\n",
      "Test Data Shape: (53871, 2)\n",
      "\n",
      "Validation Data Shape: (53871, 2)\n"
     ]
    }
   ],
   "source": [
    "# Display basic information\n",
    "print(\"Training Data Shape:\", train_data.shape)\n",
    "print(\"\\nTest Data Shape:\", test_data.shape)\n",
    "print(\"\\nValidation Data Shape:\", val_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c325ee24-2884-4d1e-9dc6-e97a88fd7e2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First few rows of training data:\n",
      "                                            sentence  label\n",
      "0                               feel submissive ever      4\n",
      "1            feel playful enough try new combination      2\n",
      "2  find broken piece feeling nothing feeling noth...      0\n",
      "3  feel ecstatic worry make love automatic adica ...      2\n",
      "4  ive feeling really jealous friend rafia im ash...      0\n"
     ]
    }
   ],
   "source": [
    "# Display first few rows\n",
    "print(\"\\nFirst few rows of training data:\")\n",
    "print(train_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1bf778a3-1e38-409d-a6eb-e72c5de465d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize GPT-2 tokenizer\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "max_tokens = 512  # Maximum sequence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "534425e0-57ff-4668-ad81-9f4b54460ecd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tokenizing texts...\n"
     ]
    }
   ],
   "source": [
    "def tokenize_text(text):\n",
    "    # Ensure text is a string\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    \n",
    "    # Handle 'nan' values\n",
    "    if text == 'nan' or pd.isna(text):\n",
    "        text = \"\"\n",
    "        \n",
    "    # Tokenize the text\n",
    "    tokens = tokenizer.encode(text)\n",
    "    \n",
    "    # Truncate if longer than max_tokens\n",
    "    if len(tokens) > max_tokens:\n",
    "        tokens = tokens[:max_tokens]\n",
    "    # Pad if shorter than max_tokens\n",
    "    elif len(tokens) < max_tokens:\n",
    "        tokens = tokens + [tokenizer.eot_token] * (max_tokens - len(tokens))\n",
    "    return tokens\n",
    "\n",
    "# Tokenize all texts\n",
    "print(\"\\nTokenizing texts...\")\n",
    "X_train = torch.tensor([tokenize_text(text) for text in train_data['sentence']], dtype=torch.float32).to(device)\n",
    "X_test = torch.tensor([tokenize_text(text) for text in test_data['sentence']], dtype=torch.float32).to(device)\n",
    "X_val = torch.tensor([tokenize_text(text) for text in val_data['sentence']], dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d731a029-3f73-46fa-8905-96d826d70d63",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[36410.,   850., 33532.,  ..., 50256., 50256., 50256.],\n",
       "        [36410., 34264.,  1576.,  ..., 50256., 50256., 50256.],\n",
       "        [19796.,  5445.,  3704.,  ..., 50256., 50256., 50256.],\n",
       "        ...,\n",
       "        [ 5460.,   736.,  1310.,  ..., 50256., 50256., 50256.],\n",
       "        [36410., 20488., 26343.,  ..., 50256., 50256., 50256.],\n",
       "        [36410.,  2138.,  6655.,  ..., 50256., 50256., 50256.]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "31153977-1849-46aa-a43e-86307db0c161",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get labels directly from the datasets\n",
    "y_train = torch.tensor(train_data['label'].values, dtype=torch.long).to(device)\n",
    "y_test = torch.tensor(test_data['label'].values, dtype=torch.long).to(device)\n",
    "y_val = torch.tensor(val_data['label'].values, dtype=torch.long).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "969ec509-4361-452d-aa91-692262d6f2c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of classes: 6\n",
      "Classes: [0 1 2 3 4 5]\n",
      "\n",
      "Tokenized sequence shape: torch.Size([161613, 512])\n"
     ]
    }
   ],
   "source": [
    "# Get unique classes\n",
    "num_classes = len(np.unique(y_train.cpu().numpy()))\n",
    "print(\"\\nNumber of classes:\", num_classes)\n",
    "print(\"Classes:\", np.unique(y_train.cpu().numpy()))\n",
    "print(\"\\nTokenized sequence shape:\", X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "14e936cc-8a22-4ef9-bc26-b01fe7c9d677",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SoftmaxRegression(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(SoftmaxRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7420895d-5c6c-40a8-b8ae-ee98eb595787",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize model and move to GPU\n",
    "model = SoftmaxRegression(X_train.shape[1], num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0f4f6b6e-c9e1-4484-a868-7a842bda7859",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training loop\n",
    "num_epochs = 1000\n",
    "batch_size = 1024\n",
    "n_samples = len(X_train)\n",
    "n_batches = (n_samples + batch_size - 1) // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f30b24-08dc-4bdf-9a4a-25ce3f0e3b52",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model...\n",
      "Epoch [100/1000], Loss: 46509853009.0127, Validation Accuracy: 17.48%\n",
      "Epoch [200/1000], Loss: 46259554375.2911, Validation Accuracy: 21.49%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTraining model...\")\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    # Shuffle the data\n",
    "    indices = torch.randperm(n_samples)\n",
    "    X_train_shuffled = X_train[indices]\n",
    "    y_train_shuffled = y_train[indices]\n",
    "    \n",
    "    for i in range(n_batches):\n",
    "        start_idx = i * batch_size\n",
    "        end_idx = min((i + 1) * batch_size, n_samples)\n",
    "        \n",
    "        batch_X = X_train_shuffled[start_idx:end_idx]\n",
    "        batch_y = y_train_shuffled[start_idx:end_idx]\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    # Calculate validation accuracy\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(X_val)\n",
    "        val_pred = torch.argmax(val_outputs, dim=1)\n",
    "        val_accuracy = (val_pred == y_val).float().mean()\n",
    "    \n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/n_batches:.4f}, Validation Accuracy: {val_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ad9b7d-b3dd-40b1-9146-8659088b1c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Validation accuracy\n",
    "    val_outputs = model(X_val)\n",
    "    val_pred = torch.argmax(val_outputs, dim=1)\n",
    "    val_accuracy = (val_pred == y_val).float().mean()\n",
    "    print(f\"\\nValidation Accuracy: {val_accuracy*100:.2f}%\")\n",
    "    \n",
    "    # Test accuracy\n",
    "    test_outputs = model(X_test)\n",
    "    test_pred = torch.argmax(test_outputs, dim=1)\n",
    "    test_accuracy = (test_pred == y_test).float().mean()\n",
    "    print(f\"Test Accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4651b531-266f-4ee8-8ac5-f8f959b0d875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test.cpu().numpy(), test_pred.cpu().numpy(), \n",
    "                          target_names=np.unique(y_train.cpu().numpy())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9cdb0e-c48e-41db-adb8-eaacc4f5dacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "cm = confusion_matrix(y_test.cpu().numpy(), test_pred.cpu().numpy())\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=np.unique(y_train.cpu().numpy()),\n",
    "            yticklabels=np.unique(y_train.cpu().numpy()))\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba389f6-1b84-4ac2-82a5-68dc5ebb7d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict sentiment for new text\n",
    "def predict_sentiment(text):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Tokenize the text using GPT-2 tokenizer\n",
    "        text_tokens = torch.tensor([tokenize_text(text)], dtype=torch.float32).to(device)\n",
    "        \n",
    "        # Get prediction\n",
    "        outputs = model(text_tokens)\n",
    "        probabilities = torch.softmax(outputs, dim=1)[0]\n",
    "        prediction = torch.argmax(probabilities).item()\n",
    "        \n",
    "        return np.unique(y_train.cpu().numpy())[prediction], probabilities.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1de5ba4-61f8-4cdd-a353-2d376e2c9238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example predictions\n",
    "example_texts = input()\n",
    "\n",
    "for text in example_texts:\n",
    "    sentiment, probs = predict_sentiment(text)\n",
    "    print(f\"\\nText: {text}\")\n",
    "    print(f\"Predicted sentiment: {sentiment}\")\n",
    "    print(\"Probability distribution:\")\n",
    "    for label, prob in zip(np.unique(y_train.cpu().numpy()), probs):\n",
    "        print(f\"{label}: {prob:.4f}\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (projectml)",
   "language": "python",
   "name": "projectml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
