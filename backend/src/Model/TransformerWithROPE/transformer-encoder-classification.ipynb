{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Needed Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "CqdCyBPJAWkD",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import tiktoken\n",
    "import re, string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk, subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPU:  1\n",
      "CUDA available: True\n",
      "CUDA version: 12.6\n",
      "GPU device name: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of GPU: \", torch.cuda.device_count())\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "print(f\"GPU device name: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'No GPU'}\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Split the dataset into Train, Validation, Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../Dataset/Processed dataset/processed_data.csv')\n",
    "train_df = pd.read_csv(\"../../Dataset/Processed dataset/train_data.csv\")\n",
    "test_df = pd.read_csv(\"../../Dataset/Processed dataset/test_data.csv\")\n",
    "validation_df = pd.read_csv(\"../../Dataset/Processed dataset/validation_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 161613\n",
      "Validation set size: 53871\n",
      "Test set size: 53871\n"
     ]
    }
   ],
   "source": [
    "# Display split sizes\n",
    "print(f\"Training set size: {len(train_df)}\")\n",
    "print(f\"Validation set size: {len(validation_df)}\")\n",
    "print(f\"Test set size: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>feel submissive ever</td>\n",
       "      <td>sadness</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>feel playful enough try new combination</td>\n",
       "      <td>joy</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>find broken piece feeling nothing feeling noth...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>feel ecstatic worry make love automatic adica ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ive feeling really jealous friend rafia im ash...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161608</th>\n",
       "      <td>feeling nervous</td>\n",
       "      <td>fear</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161609</th>\n",
       "      <td>feel like punished believing austin</td>\n",
       "      <td>sadness</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161610</th>\n",
       "      <td>look back little paragraph ive written feel bi...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161611</th>\n",
       "      <td>feel inconvenienced trimmer blade dull</td>\n",
       "      <td>sadness</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161612</th>\n",
       "      <td>feel rather surprised claimed swedish prosecut...</td>\n",
       "      <td>surprise</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>161613 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 sentence sentiment  label\n",
       "0                                    feel submissive ever   sadness      4\n",
       "1                 feel playful enough try new combination       joy      2\n",
       "2       find broken piece feeling nothing feeling noth...     anger      0\n",
       "3       feel ecstatic worry make love automatic adica ...       joy      2\n",
       "4       ive feeling really jealous friend rafia im ash...     anger      0\n",
       "...                                                   ...       ...    ...\n",
       "161608                                    feeling nervous      fear      1\n",
       "161609                feel like punished believing austin   sadness      4\n",
       "161610  look back little paragraph ive written feel bi...     anger      0\n",
       "161611             feel inconvenienced trimmer blade dull   sadness      4\n",
       "161612  feel rather surprised claimed swedish prosecut...  surprise      5\n",
       "\n",
       "[161613 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>feeling lake popular weekend summer huge parki...</td>\n",
       "      <td>joy</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>couldnt stop feeling threatened card grandmoth...</td>\n",
       "      <td>fear</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>feel way try ignored ignored got interested es...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>feeling bitchy</td>\n",
       "      <td>anger</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>know little feel special bond</td>\n",
       "      <td>joy</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53866</th>\n",
       "      <td>think bottom line b story pierce feel need acc...</td>\n",
       "      <td>love</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53867</th>\n",
       "      <td>straight man ejacalute like week sexual intere...</td>\n",
       "      <td>love</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53868</th>\n",
       "      <td>feel really rude stating fact would feel rude ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53869</th>\n",
       "      <td>im feeling especially triggered grumpy note ev...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53870</th>\n",
       "      <td>feel useless home</td>\n",
       "      <td>sadness</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53871 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence sentiment  label\n",
       "0      feeling lake popular weekend summer huge parki...       joy      2\n",
       "1      couldnt stop feeling threatened card grandmoth...      fear      1\n",
       "2      feel way try ignored ignored got interested es...   sadness      4\n",
       "3                                         feeling bitchy     anger      0\n",
       "4                          know little feel special bond       joy      2\n",
       "...                                                  ...       ...    ...\n",
       "53866  think bottom line b story pierce feel need acc...      love      3\n",
       "53867  straight man ejacalute like week sexual intere...      love      3\n",
       "53868  feel really rude stating fact would feel rude ...     anger      0\n",
       "53869  im feeling especially triggered grumpy note ev...     anger      0\n",
       "53870                                  feel useless home   sadness      4\n",
       "\n",
       "[53871 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                 im feeling cold im alone\n",
       "1        feel like im th grade shy wouldnt say anything...\n",
       "2                           feel like navy dress dangerous\n",
       "3                               feel jaded chaser although\n",
       "4                  feel petty vicious mean defensive angry\n",
       "                               ...                        \n",
       "53866    feeling especially tender tendency get weepy h...\n",
       "53867    pryers feel like listening perhaps punished ba...\n",
       "53868    promise never react even grievously provoked l...\n",
       "53869                              feel submissive spoiled\n",
       "53870    go period feeling like one could love unremark...\n",
       "Name: sentence, Length: 53871, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "2    36000\n",
       "0    34341\n",
       "4    33000\n",
       "1    28598\n",
       "3    20699\n",
       "5     8975\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4: 'sadness', 2: 'joy', 0: 'anger', 3: 'love', 5: 'surprise', 1: 'fear'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dict = dict(zip(train_df['label'], train_df['sentiment']))\n",
    "label_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Normalize Dataset With Tokenization And Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Lt6pqhFIAYSX",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, device):\n",
    "        # Make sure all text values are strings\n",
    "        self.text = dataframe['sentence'].astype(str).values\n",
    "        self.labels = dataframe['label'].values\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = device\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.text[idx]\n",
    "        label = self.labels[idx]\n",
    "        # Convert 'nan' to empty string if necessary\n",
    "        if text == 'nan':\n",
    "            text = ''\n",
    "        encoding = self.tokenizer.encode(text)\n",
    "        input_ids = torch.tensor(encoding, dtype=torch.long, device=self.device)\n",
    "        label = torch.tensor(label, dtype=torch.long, device=self.device)\n",
    "        return input_ids, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = tokenizer.encode(train_df['sentence'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[36410, 850, 33532, 1683]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "jdZcu7ZKBVBZ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "\n",
    "tokenizer = tiktoken.get_encoding('gpt2')\n",
    "\n",
    "# Create datasets with device\n",
    "train_dataset = TextDataset(train_df, tokenizer, device)\n",
    "val_dataset = TextDataset(validation_df, tokenizer, device)\n",
    "test_dataset = TextDataset(test_df, tokenizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pryUvgK7ETbY",
    "outputId": "b1a06135-0920-43a7-f8ea-795d841e0f8c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([36410,   850, 33532,  1683], device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for input_ids, label in train_dataset:\n",
    "    print(input_ids)\n",
    "    print(label)\n",
    "    break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Set Up Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "7LOszNGrAZRy",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    input_ids = [item[0] for item in batch]\n",
    "    labels = [item[1] for item in batch]\n",
    "    max_length = max(len(ids) for ids in input_ids)\n",
    "    \n",
    "    # All tensors should already be on the correct device from the dataset\n",
    "    device = input_ids[0].device\n",
    "    \n",
    "    input_ids = torch.stack([\n",
    "        torch.cat([ids, torch.zeros(max_length - len(ids), dtype=torch.long, device=device)]) \n",
    "        for ids in input_ids\n",
    "    ])\n",
    "    labels = torch.stack(labels)\n",
    "    return input_ids, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "yxaHUt79BV5c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create dataloaders\n",
    "batch_size = 128\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Initialize Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from TransformerEncoderROPE import TransformerModelWithROPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "wfFQKb4-BX1q",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize the Transformer model\n",
    "vocab_size = tokenizer.n_vocab\n",
    "embed_size = 256\n",
    "d_model = 256\n",
    "num_heads = 8\n",
    "d_ff = 512\n",
    "output_size = len(train_df['label'].unique())\n",
    "num_layers = 3\n",
    "dropout = 0.2\n",
    "\n",
    "# Initialize model and move to device\n",
    "#model = TransformerModel(vocab_size, embed_size, d_model, num_heads, d_ff, output_size, num_layers, dropout)\n",
    "model = TransformerModelWithROPE(vocab_size, embed_size, d_model, num_heads, d_ff, output_size, num_layers, dropout)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for input_ids, labels in val_dataloader:\\n    outputs = model(input_ids)\\n    print(outputs.size())\\n    print(outputs)\\n    print()\\n    print(torch.max(outputs,1))\\n    print()\\n    _, predicted = torch.max(outputs,1)\\n    print(_)\\n    print(predicted)\\n    break\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''for input_ids, labels in val_dataloader:\n",
    "    outputs = model(input_ids)\n",
    "    print(outputs.size())\n",
    "    print(outputs)\n",
    "    print()\n",
    "    print(torch.max(outputs,1))\n",
    "    print()\n",
    "    _, predicted = torch.max(outputs,1)\n",
    "    print(_)\n",
    "    print(predicted)\n",
    "    break\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the accuracy function (using the first version from before)\n",
    "def calculate_accuracy(outputs, labels):\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    total = labels.size(0)\n",
    "    correct = (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy, correct, total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training loop with model saving\n",
    "best_val_accuracy = 0.0  # Track the best validation accuracy\n",
    "best_model_path = '../../Saved trained model/best_transformerROPE_model.pth'  # File path to save the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426
    },
    "id": "TCDm8oP1BaMl",
    "outputId": "b0540645-1ca9-40d4-df6a-35af6b69c03b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Loss: 0.3139\n",
      "Correct/Total: 138160/161613, Training Accuracy after Epoch 1: 85.49%\n",
      "Correct/Total: 46973/53871, Validation Accuracy after Epoch 1: 87.20%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training step\n",
    "    model.train()\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    for input_ids, labels in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Calculate training accuracy\n",
    "        batch_acc, batch_correct, batch_total = calculate_accuracy(outputs, labels)\n",
    "        train_correct += batch_correct\n",
    "        train_total += batch_total\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    train_accuracy = 100 * train_correct / train_total\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}\")\n",
    "    print(f\"Correct/Total: {train_correct}/{train_total}, Training Accuracy after Epoch {epoch+1}: {train_accuracy:.2f}%\")\n",
    "\n",
    "    # Validation step\n",
    "    model.eval()\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for input_ids, labels in val_dataloader:\n",
    "            outputs = model(input_ids)\n",
    "            batch_acc, batch_correct, batch_total = calculate_accuracy(outputs, labels)\n",
    "            val_correct += batch_correct\n",
    "            val_total += batch_total\n",
    "\n",
    "    val_accuracy = 100 * val_correct / val_total\n",
    "    print(f\"Correct/Total: {val_correct}/{val_total}, Validation Accuracy after Epoch {epoch+1}: {val_accuracy:.2f}%\")\n",
    "\n",
    "    # Save model if validation accuracy improves\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "    \n",
    "    print()  # Add a blank line for readability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Evaluation On Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerModelWithROPE(\n",
       "  (embedding): Embedding(50257, 256)\n",
       "  (encoder_layers): ModuleList(\n",
       "    (0-2): 3 x TransformerEncoderLayerWithROPE(\n",
       "      (rotary_emb): RotaryEmbedding()\n",
       "      (wq): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (wk): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (wv): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (feed_forward): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=512, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=512, out_features=256, bias=True)\n",
       "      )\n",
       "      (layernorm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (layernorm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=256, out_features=6, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming the same model architecture\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "model.eval()  # Set to evaluation mode if using for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct/Total: 47266/53871, Accuracy: 87.74%\n"
     ]
    }
   ],
   "source": [
    "test_correct, test_total = 0, 0\n",
    "\n",
    "for input_ids, labels in test_dataloader:\n",
    "    outputs = model(input_ids)\n",
    "    batch_acc, batch_correct, batch_total = calculate_accuracy(outputs, labels)\n",
    "    test_correct += batch_correct\n",
    "    test_total += batch_total\n",
    "\n",
    "test_accuracy = 100 * test_correct / test_total\n",
    "print(f\"Correct/Total: {test_correct}/{test_total}, Accuracy: {test_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Example Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_emotion(sentence, model, tokenizer, device):\n",
    "    # Preprocess the input sentence\n",
    "    sentence = sentence.lower()\n",
    "    encoding = tokenizer.encode(sentence)\n",
    "    input_ids = torch.tensor(encoding, dtype=torch.long, device=device).unsqueeze(0)\n",
    "    \n",
    "    # Make prediction\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids)\n",
    "        accuracy, predicted = torch.max(outputs, 1)\n",
    "          \n",
    "    return label_dict[predicted.item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m test_sentence = \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m predicted_emotion = predict_emotion(test_sentence, model, tokenizer, device)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSentence: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_sentence\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\projectml\\Lib\\site-packages\\ipykernel\\kernelbase.py:1282\u001b[39m, in \u001b[36mKernel.raw_input\u001b[39m\u001b[34m(self, prompt)\u001b[39m\n\u001b[32m   1280\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1281\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[32m-> \u001b[39m\u001b[32m1282\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1283\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1284\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mshell\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1285\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mshell\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1286\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1287\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\projectml\\Lib\\site-packages\\ipykernel\\kernelbase.py:1325\u001b[39m, in \u001b[36mKernel._input_request\u001b[39m\u001b[34m(self, prompt, ident, parent, password)\u001b[39m\n\u001b[32m   1322\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[32m   1323\u001b[39m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[32m   1324\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mInterrupted by user\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1325\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1326\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1327\u001b[39m     \u001b[38;5;28mself\u001b[39m.log.warning(\u001b[33m\"\u001b[39m\u001b[33mInvalid Message:\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "test_sentence = input()\n",
    "predicted_emotion = predict_emotion(test_sentence, model, tokenizer, device)\n",
    "print(f\"Sentence: {test_sentence}\")\n",
    "print(f\"Predicted emotion: {predicted_emotion}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 605165,
     "sourceId": 1085454,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python (projectml)",
   "language": "python",
   "name": "projectml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
