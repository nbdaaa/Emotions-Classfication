{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1085454,"sourceType":"datasetVersion","datasetId":605165}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install tiktoken","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mqdeu9K-AKOJ","outputId":"5fc87627-cbcf-4634-9e02-81de90e5cb6e","trusted":true,"execution":{"iopub.status.busy":"2025-03-14T03:47:25.267997Z","iopub.execute_input":"2025-03-14T03:47:25.268301Z","iopub.status.idle":"2025-03-14T03:47:29.341881Z","shell.execute_reply.started":"2025-03-14T03:47:25.268273Z","shell.execute_reply":"2025-03-14T03:47:29.341106Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.9.0)\nRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.11.6)\nRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.32.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport tiktoken\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split","metadata":{"id":"CqdCyBPJAWkD","trusted":true,"execution":{"iopub.status.busy":"2025-03-14T03:47:29.343043Z","iopub.execute_input":"2025-03-14T03:47:29.343355Z","iopub.status.idle":"2025-03-14T03:47:31.734908Z","shell.execute_reply.started":"2025-03-14T03:47:29.343327Z","shell.execute_reply":"2025-03-14T03:47:31.734244Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Read datasets\ntrain_df = pd.read_csv('/kaggle/input/emotions-dataset-for-nlp/train.txt', names=['text', 'emotion'], sep=';')\nvalidation_df = pd.read_csv('/kaggle/input/emotions-dataset-for-nlp/val.txt', names=['text', 'emotion'], sep=';')\ntest_df = pd.read_csv('/kaggle/input/emotions-dataset-for-nlp/test.txt', names=['text', 'emotion'], sep=';')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T03:47:31.736225Z","iopub.execute_input":"2025-03-14T03:47:31.736666Z","iopub.status.idle":"2025-03-14T03:47:31.819097Z","shell.execute_reply.started":"2025-03-14T03:47:31.736641Z","shell.execute_reply":"2025-03-14T03:47:31.818516Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"train_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T03:47:31.820380Z","iopub.execute_input":"2025-03-14T03:47:31.820640Z","iopub.status.idle":"2025-03-14T03:47:31.845694Z","shell.execute_reply.started":"2025-03-14T03:47:31.820607Z","shell.execute_reply":"2025-03-14T03:47:31.844889Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                                    text  emotion\n0                                i didnt feel humiliated  sadness\n1      i can go from feeling so hopeless to so damned...  sadness\n2       im grabbing a minute to post i feel greedy wrong    anger\n3      i am ever feeling nostalgic about the fireplac...     love\n4                                   i am feeling grouchy    anger\n...                                                  ...      ...\n15995  i just had a very brief time in the beanbag an...  sadness\n15996  i am now turning and i feel pathetic that i am...  sadness\n15997                     i feel strong and good overall      joy\n15998  i feel like this was such a rude comment and i...    anger\n15999  i know a lot but i feel so stupid because i ca...  sadness\n\n[16000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>emotion</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>i didnt feel humiliated</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>i can go from feeling so hopeless to so damned...</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>im grabbing a minute to post i feel greedy wrong</td>\n      <td>anger</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>i am ever feeling nostalgic about the fireplac...</td>\n      <td>love</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>i am feeling grouchy</td>\n      <td>anger</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>15995</th>\n      <td>i just had a very brief time in the beanbag an...</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>15996</th>\n      <td>i am now turning and i feel pathetic that i am...</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>15997</th>\n      <td>i feel strong and good overall</td>\n      <td>joy</td>\n    </tr>\n    <tr>\n      <th>15998</th>\n      <td>i feel like this was such a rude comment and i...</td>\n      <td>anger</td>\n    </tr>\n    <tr>\n      <th>15999</th>\n      <td>i know a lot but i feel so stupid because i ca...</td>\n      <td>sadness</td>\n    </tr>\n  </tbody>\n</table>\n<p>16000 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"validation_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T03:47:31.846545Z","iopub.execute_input":"2025-03-14T03:47:31.846828Z","iopub.status.idle":"2025-03-14T03:47:31.854909Z","shell.execute_reply.started":"2025-03-14T03:47:31.846799Z","shell.execute_reply":"2025-03-14T03:47:31.854271Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                                   text  emotion\n0     im feeling quite sad and sorry for myself but ...  sadness\n1     i feel like i am still looking at a blank canv...  sadness\n2                        i feel like a faithful servant     love\n3                     i am just feeling cranky and blue    anger\n4     i can have for a treat or if i am feeling festive      joy\n...                                                 ...      ...\n1995  im having ssa examination tomorrow in the morn...  sadness\n1996  i constantly worry about their fight against n...      joy\n1997  i feel its important to share this info for th...      joy\n1998  i truly feel that if you are passionate enough...      joy\n1999  i feel like i just wanna buy any cute make up ...      joy\n\n[2000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>emotion</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>im feeling quite sad and sorry for myself but ...</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>i feel like i am still looking at a blank canv...</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>i feel like a faithful servant</td>\n      <td>love</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>i am just feeling cranky and blue</td>\n      <td>anger</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>i can have for a treat or if i am feeling festive</td>\n      <td>joy</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1995</th>\n      <td>im having ssa examination tomorrow in the morn...</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>1996</th>\n      <td>i constantly worry about their fight against n...</td>\n      <td>joy</td>\n    </tr>\n    <tr>\n      <th>1997</th>\n      <td>i feel its important to share this info for th...</td>\n      <td>joy</td>\n    </tr>\n    <tr>\n      <th>1998</th>\n      <td>i truly feel that if you are passionate enough...</td>\n      <td>joy</td>\n    </tr>\n    <tr>\n      <th>1999</th>\n      <td>i feel like i just wanna buy any cute make up ...</td>\n      <td>joy</td>\n    </tr>\n  </tbody>\n</table>\n<p>2000 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"test_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T03:47:31.855643Z","iopub.execute_input":"2025-03-14T03:47:31.855915Z","iopub.status.idle":"2025-03-14T03:47:31.872011Z","shell.execute_reply.started":"2025-03-14T03:47:31.855888Z","shell.execute_reply":"2025-03-14T03:47:31.871363Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                                   text  emotion\n0     im feeling rather rotten so im not very ambiti...  sadness\n1             im updating my blog because i feel shitty  sadness\n2     i never make her separate from me because i do...  sadness\n3     i left with my bouquet of red and yellow tulip...      joy\n4       i was feeling a little vain when i did this one  sadness\n...                                                 ...      ...\n1995  i just keep feeling like someone is being unki...    anger\n1996  im feeling a little cranky negative after this...    anger\n1997  i feel that i am useful to my people and that ...      joy\n1998  im feeling more comfortable with derby i feel ...      joy\n1999  i feel all weird when i have to meet w people ...     fear\n\n[2000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>emotion</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>im feeling rather rotten so im not very ambiti...</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>im updating my blog because i feel shitty</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>i never make her separate from me because i do...</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>i left with my bouquet of red and yellow tulip...</td>\n      <td>joy</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>i was feeling a little vain when i did this one</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1995</th>\n      <td>i just keep feeling like someone is being unki...</td>\n      <td>anger</td>\n    </tr>\n    <tr>\n      <th>1996</th>\n      <td>im feeling a little cranky negative after this...</td>\n      <td>anger</td>\n    </tr>\n    <tr>\n      <th>1997</th>\n      <td>i feel that i am useful to my people and that ...</td>\n      <td>joy</td>\n    </tr>\n    <tr>\n      <th>1998</th>\n      <td>im feeling more comfortable with derby i feel ...</td>\n      <td>joy</td>\n    </tr>\n    <tr>\n      <th>1999</th>\n      <td>i feel all weird when i have to meet w people ...</td>\n      <td>fear</td>\n    </tr>\n  </tbody>\n</table>\n<p>2000 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\n# Transform labels\nle = LabelEncoder()\ntrain_df['label'] = le.fit_transform(train_df['emotion'])\nvalidation_df['label'] = le.transform(validation_df['emotion'])\ntest_df['label'] = le.transform(test_df['emotion'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T03:47:31.872760Z","iopub.execute_input":"2025-03-14T03:47:31.873049Z","iopub.status.idle":"2025-03-14T03:47:31.889872Z","shell.execute_reply.started":"2025-03-14T03:47:31.873019Z","shell.execute_reply":"2025-03-14T03:47:31.889208Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"train_df.label.value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T03:47:31.890594Z","iopub.execute_input":"2025-03-14T03:47:31.890778Z","iopub.status.idle":"2025-03-14T03:47:31.910587Z","shell.execute_reply.started":"2025-03-14T03:47:31.890761Z","shell.execute_reply":"2025-03-14T03:47:31.909871Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"label\n2    5362\n4    4666\n0    2159\n1    1937\n3    1304\n5     572\nName: count, dtype: int64"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"label_dict = dict(zip(train_df['label'], train_df['emotion']))\nlabel_dict","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T03:47:31.913048Z","iopub.execute_input":"2025-03-14T03:47:31.913235Z","iopub.status.idle":"2025-03-14T03:47:31.927650Z","shell.execute_reply.started":"2025-03-14T03:47:31.913218Z","shell.execute_reply":"2025-03-14T03:47:31.926780Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"{4: 'sadness', 0: 'anger', 3: 'love', 5: 'surprise', 1: 'fear', 2: 'joy'}"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"class TextDataset(Dataset):\n    def __init__(self, dataframe, tokenizer, device):\n        self.text = dataframe['text'].str.lower().values\n        self.labels = dataframe['label'].values\n        self.tokenizer = tokenizer\n        self.device = device\n\n    def __len__(self):\n        return len(self.text)\n\n    def __getitem__(self, idx):\n        text = self.text[idx]\n        label = self.labels[idx]\n        encoding = self.tokenizer.encode(text)\n        input_ids = torch.tensor(encoding, dtype=torch.long, device=self.device)\n        label = torch.tensor(label, dtype=torch.long, device=self.device)\n        return input_ids, label","metadata":{"id":"Lt6pqhFIAYSX","trusted":true,"execution":{"iopub.status.busy":"2025-03-14T03:47:31.929282Z","iopub.execute_input":"2025-03-14T03:47:31.929492Z","iopub.status.idle":"2025-03-14T03:47:31.940847Z","shell.execute_reply.started":"2025-03-14T03:47:31.929473Z","shell.execute_reply":"2025-03-14T03:47:31.940145Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def collate_fn(batch):\n    input_ids = [item[0] for item in batch]\n    labels = [item[1] for item in batch]\n    max_length = max(len(ids) for ids in input_ids)\n    \n    # All tensors should already be on the correct device from the dataset\n    device = input_ids[0].device\n    \n    input_ids = torch.stack([\n        torch.cat([ids, torch.zeros(max_length - len(ids), dtype=torch.long, device=device)]) \n        for ids in input_ids\n    ])\n    labels = torch.stack(labels)\n    return input_ids, labels","metadata":{"id":"7LOszNGrAZRy","trusted":true,"execution":{"iopub.status.busy":"2025-03-14T03:47:31.941584Z","iopub.execute_input":"2025-03-14T03:47:31.941877Z","iopub.status.idle":"2025-03-14T03:47:31.955238Z","shell.execute_reply.started":"2025-03-14T03:47:31.941849Z","shell.execute_reply":"2025-03-14T03:47:31.954573Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nclass TransformerEncoderLayer(nn.Module):\n    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n        super(TransformerEncoderLayer, self).__init__()\n        self.num_heads = num_heads\n        self.d_model = d_model\n        self.depth = d_model // num_heads\n\n        # Linear layers for Q, K, V matrices\n        self.wq = nn.Linear(d_model, d_model)  # (batch_size, seq_len, d_model) -> (batch_size, seq_len, d_model)\n        self.wk = nn.Linear(d_model, d_model)  # (batch_size, seq_len, d_model) -> (batch_size, seq_len, d_model)\n        self.wv = nn.Linear(d_model, d_model)  # (batch_size, seq_len, d_model) -> (batch_size, seq_len, d_model)\n\n        # Output linear transformation\n        self.dense = nn.Linear(d_model, d_model)  # (batch_size, seq_len, d_model) -> (batch_size, seq_len, d_model)   self.\n\n        # Feed-forward network\n        self.feed_forward = nn.Sequential(\n            nn.Linear(d_model, d_ff),  # (batch_size, seq_len, d_model) -> (batch_size, seq_len, d_ff)\n            nn.ReLU(),\n            nn.Linear(d_ff, d_model)  # (batch_size, seq_len, d_ff) -> (batch_size, seq_len, d_model)\n        )\n\n        # Layer normalization and dropout\n        self.layernorm1 = nn.LayerNorm(d_model)  # (batch_size, seq_len, d_model) -> (batch_size, seq_len, d_model)\n        self.layernorm2 = nn.LayerNorm(d_model)  # (batch_size, seq_len, d_model) -> (batch_size, seq_len, d_model)\n        self.dropout = nn.Dropout(dropout)\n\n    def split_heads(self, x, batch_size):\n        # Split the last dimension into (num_heads, depth)\n        x = x.view(batch_size, -1, self.num_heads, self.depth)  # (batch_size, seq_len, d_model) -> (batch_size, seq_len, num_heads, depth)\n        # Transpose the result to shape (batch_size, num_heads, seq_len, depth)\n        return x.transpose(1, 2)  # (batch_size, seq_len, num_heads, depth) -> (batch_size, num_heads, seq_len, depth)\n\n    def scaled_dot_product_attention(self, q, k, v, mask=None):\n        matmul_qk = torch.matmul(q, k.transpose(-2, -1))  # (batch_size, num_heads, seq_len_q, seq_len_k)\n        dk = torch.tensor(k.size(-1), dtype=torch.float32)  # scalar\n        scaled_attention_logits = matmul_qk / torch.sqrt(dk)  # (batch_size, num_heads, seq_len_q, seq_len_k)\n\n        if mask is not None:\n            scaled_attention_logits = scaled_attention_logits.masked_fill(mask == 0, -1e9)\n\n        attention_weights = torch.nn.functional.softmax(scaled_attention_logits, dim=-1)  # (batch_size, num_heads, seq_len_q, seq_len_k)\n        output = torch.matmul(attention_weights, v)  # (batch_size, num_heads, seq_len_q, depth_v)\n\n        return output, attention_weights  # (batch_size, num_heads, seq_len_q, depth_v), (batch_size, num_heads, seq_len_q, seq_len_k)\n\n    def forward(self, x, mask=None):\n        batch_size = x.size(0)  # (batch_size, seq_len, d_model)\n\n        # Apply linear layers and split into heads\n        q = self.split_heads(self.wq(x), batch_size)  # (batch_size, num_heads, seq_len, depth)\n        k = self.split_heads(self.wk(x), batch_size)  # (batch_size, num_heads, seq_len, depth)\n        v = self.split_heads(self.wv(x), batch_size)  # (batch_size, num_heads, seq_len, depth)\n\n        # Apply the custom scaled dot-product attention\n        scaled_attention, _ = self.scaled_dot_product_attention(q, k, v, mask)  # (batch_size, num_heads, seq_len_q, depth_v)\n\n        # Transpose and reshape back to (batch_size, seq_len, d_model)\n        scaled_attention = scaled_attention.transpose(1, 2).contiguous()  # (batch_size, seq_len, num_heads, depth)\n        concat_attention = scaled_attention.view(batch_size, -1, self.d_model)  # (batch_size, seq_len, d_model)\n\n        # Apply the final linear layer to combine the heads\n        attn_output = self.dense(concat_attention)  # (batch_size, seq_len, d_model)\n\n        # Add & Norm\n        x = self.layernorm1(x + self.dropout(attn_output))  # (batch_size, seq_len, d_model)\n\n        # Feed-forward\n        ff_output = self.feed_forward(x)  # (batch_size, seq_len, d_model)\n\n        # Add & Norm\n        x = self.layernorm2(x + self.dropout(ff_output))  # (batch_size, seq_len, d_model)\n\n        return x  # (batch_size, seq_len, d_model)\n","metadata":{"id":"g1rriEeAAcKm","trusted":true,"execution":{"iopub.status.busy":"2025-03-14T03:47:31.955914Z","iopub.execute_input":"2025-03-14T03:47:31.956115Z","iopub.status.idle":"2025-03-14T03:47:31.969024Z","shell.execute_reply.started":"2025-03-14T03:47:31.956097Z","shell.execute_reply":"2025-03-14T03:47:31.968424Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"![](https://storage.googleapis.com/mle-courses-prod/users/61b6fa1ba83a7e37c8309756/private-files/2dc6f3e0-5fb4-11ef-9b72-9db6eacc12d1-Screen_Shot_2024_08_21_at_18.54.35.png)","metadata":{"id":"s3QlTYsoylh3"}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport math\n\nclass PositionalEncoding(nn.Module):\n    def __init__(self, d_model, max_len=5000):\n        super(PositionalEncoding, self).__init__()\n\n        # Create a long enough 'positional' tensor and fill it with positional encodings\n        # [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]\n\n        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)  # (max_len, 1)\n\n        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))  # (d_model/2,)\n\n        # Khởi tạo một tensor `pe` với các giá trị bằng 0, sẽ chứa các giá trị mã hóa vị trí (positional encodings).\n        # `pe` có dạng (max_len, d_model), trong đó `max_len` là chiều dài tối đa của chuỗi\n        # và `d_model` là chiều kích thước của embeddings của mô hình.\n        pe = torch.zeros(max_len, d_model)  # (max_len, d_model)\n\n        # Đối với tất cả các vị trí trong chuỗi (từ 0 đến max_len-1) và đối với tất cả các chỉ số chẵn trong các chiều kích thước embedding,\n        # tính toán giá trị sine của tích `position` và `div_term` và gán nó vào các vị trí tương ứng trong `pe`.\n        # Gán các giá trị sine cho mọi chiều kích thước khác của embedding (bắt đầu từ chỉ số 0).\n        # `position` có dạng (max_len, 1) và `div_term` có dạng (d_model/2,).\n        # Phép toán `position * div_term` được broadcast thành dạng (max_len, d_model/2).\n        # Kết quả được lưu trữ trong các chỉ số chẵn của `pe`, vì vậy phần được gán có dạng (max_len, d_model/2).\n        pe[:, 0::2] = torch.sin(position * div_term)  # (max_len, d_model/2)\n\n        # Tương tự, đối với tất cả các vị trí trong chuỗi và đối với tất cả các chỉ số lẻ trong các chiều kích thước embedding,\n        # tính toán giá trị cosine của tích `position` và `div_term` và gán nó vào các vị trí tương ứng trong `pe`.\n        # Gán các giá trị cosine cho các chiều kích thước còn lại của embedding (bắt đầu từ chỉ số 1).\n        # Giống như trước, `position * div_term` được broadcast thành dạng (max_len, d_model/2).\n        # Kết quả được lưu trữ trong các chỉ số lẻ của `pe`, vì vậy phần được gán có dạng (max_len, d_model/2).\n        pe[:, 1::2] = torch.cos(position * div_term)  # (max_len, d_model/2)\n\n\n        # Add a batch dimension and register it as a buffer\n        pe = pe.unsqueeze(0)  # (1, max_len, d_model)\n        self.register_buffer('pe', pe)  # Register as buffer so it's not a parameter\n\n    def forward(self, x):\n        # x: (batch_size, seq_len, d_model)\n        x = x + self.pe[:, :x.size(1), :]  # Add positional encoding, (batch_size, seq_len, d_model)\n        return x  # (batch_size, seq_len, d_model)\n","metadata":{"id":"rtNUAcArIUmZ","trusted":true,"execution":{"iopub.status.busy":"2025-03-14T03:47:31.969928Z","iopub.execute_input":"2025-03-14T03:47:31.970155Z","iopub.status.idle":"2025-03-14T03:47:31.987233Z","shell.execute_reply.started":"2025-03-14T03:47:31.970136Z","shell.execute_reply":"2025-03-14T03:47:31.986546Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"class TransformerModel(nn.Module):\n    def __init__(self, vocab_size, embed_size, d_model, num_heads, d_ff, output_size, num_layers, dropout=0.1):\n        super(TransformerModel, self).__init__()\n        self.embedding = nn.Embedding(vocab_size, embed_size)\n        self.positional_encoding = PositionalEncoding(d_model)\n        self.encoder_layers = nn.ModuleList([\n            TransformerEncoderLayer(d_model, num_heads, d_ff, dropout)\n            for _ in range(num_layers)\n        ])\n        self.fc = nn.Linear(d_model, output_size)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x, mask=None):\n        x = self.embedding(x)  # (batch_size, seq_len, embed_size)\n        x = self.positional_encoding(x)  # (batch_size, seq_len, d_model)\n        for layer in self.encoder_layers:\n            x = layer(x, mask)  # (batch_size, seq_len, d_model)\n        x = x.mean(dim=1)  # (batch_size, d_model)\n        x = self.fc(self.dropout(x))  # (batch_size, output_size)\n        return x\n","metadata":{"id":"6KuAipzfAeXv","trusted":true,"execution":{"iopub.status.busy":"2025-03-14T03:47:31.987821Z","iopub.execute_input":"2025-03-14T03:47:31.987999Z","iopub.status.idle":"2025-03-14T03:47:32.005261Z","shell.execute_reply.started":"2025-03-14T03:47:31.987983Z","shell.execute_reply":"2025-03-14T03:47:32.004571Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"train_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T03:47:32.006080Z","iopub.execute_input":"2025-03-14T03:47:32.006359Z","iopub.status.idle":"2025-03-14T03:47:32.027377Z","shell.execute_reply.started":"2025-03-14T03:47:32.006331Z","shell.execute_reply":"2025-03-14T03:47:32.026560Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"                                                    text  emotion  label\n0                                i didnt feel humiliated  sadness      4\n1      i can go from feeling so hopeless to so damned...  sadness      4\n2       im grabbing a minute to post i feel greedy wrong    anger      0\n3      i am ever feeling nostalgic about the fireplac...     love      3\n4                                   i am feeling grouchy    anger      0\n...                                                  ...      ...    ...\n15995  i just had a very brief time in the beanbag an...  sadness      4\n15996  i am now turning and i feel pathetic that i am...  sadness      4\n15997                     i feel strong and good overall      joy      2\n15998  i feel like this was such a rude comment and i...    anger      0\n15999  i know a lot but i feel so stupid because i ca...  sadness      4\n\n[16000 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>emotion</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>i didnt feel humiliated</td>\n      <td>sadness</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>i can go from feeling so hopeless to so damned...</td>\n      <td>sadness</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>im grabbing a minute to post i feel greedy wrong</td>\n      <td>anger</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>i am ever feeling nostalgic about the fireplac...</td>\n      <td>love</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>i am feeling grouchy</td>\n      <td>anger</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>15995</th>\n      <td>i just had a very brief time in the beanbag an...</td>\n      <td>sadness</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>15996</th>\n      <td>i am now turning and i feel pathetic that i am...</td>\n      <td>sadness</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>15997</th>\n      <td>i feel strong and good overall</td>\n      <td>joy</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>15998</th>\n      <td>i feel like this was such a rude comment and i...</td>\n      <td>anger</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15999</th>\n      <td>i know a lot but i feel so stupid because i ca...</td>\n      <td>sadness</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n<p>16000 rows × 3 columns</p>\n</div>"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"test_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T03:47:32.028194Z","iopub.execute_input":"2025-03-14T03:47:32.028471Z","iopub.status.idle":"2025-03-14T03:47:32.042922Z","shell.execute_reply.started":"2025-03-14T03:47:32.028442Z","shell.execute_reply":"2025-03-14T03:47:32.042255Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"                                                   text  emotion  label\n0     im feeling rather rotten so im not very ambiti...  sadness      4\n1             im updating my blog because i feel shitty  sadness      4\n2     i never make her separate from me because i do...  sadness      4\n3     i left with my bouquet of red and yellow tulip...      joy      2\n4       i was feeling a little vain when i did this one  sadness      4\n...                                                 ...      ...    ...\n1995  i just keep feeling like someone is being unki...    anger      0\n1996  im feeling a little cranky negative after this...    anger      0\n1997  i feel that i am useful to my people and that ...      joy      2\n1998  im feeling more comfortable with derby i feel ...      joy      2\n1999  i feel all weird when i have to meet w people ...     fear      1\n\n[2000 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>emotion</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>im feeling rather rotten so im not very ambiti...</td>\n      <td>sadness</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>im updating my blog because i feel shitty</td>\n      <td>sadness</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>i never make her separate from me because i do...</td>\n      <td>sadness</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>i left with my bouquet of red and yellow tulip...</td>\n      <td>joy</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>i was feeling a little vain when i did this one</td>\n      <td>sadness</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1995</th>\n      <td>i just keep feeling like someone is being unki...</td>\n      <td>anger</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1996</th>\n      <td>im feeling a little cranky negative after this...</td>\n      <td>anger</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1997</th>\n      <td>i feel that i am useful to my people and that ...</td>\n      <td>joy</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1998</th>\n      <td>im feeling more comfortable with derby i feel ...</td>\n      <td>joy</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1999</th>\n      <td>i feel all weird when i have to meet w people ...</td>\n      <td>fear</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>2000 rows × 3 columns</p>\n</div>"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"validation_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T03:47:32.043769Z","iopub.execute_input":"2025-03-14T03:47:32.043974Z","iopub.status.idle":"2025-03-14T03:47:32.058279Z","shell.execute_reply.started":"2025-03-14T03:47:32.043944Z","shell.execute_reply":"2025-03-14T03:47:32.057676Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"                                                   text  emotion  label\n0     im feeling quite sad and sorry for myself but ...  sadness      4\n1     i feel like i am still looking at a blank canv...  sadness      4\n2                        i feel like a faithful servant     love      3\n3                     i am just feeling cranky and blue    anger      0\n4     i can have for a treat or if i am feeling festive      joy      2\n...                                                 ...      ...    ...\n1995  im having ssa examination tomorrow in the morn...  sadness      4\n1996  i constantly worry about their fight against n...      joy      2\n1997  i feel its important to share this info for th...      joy      2\n1998  i truly feel that if you are passionate enough...      joy      2\n1999  i feel like i just wanna buy any cute make up ...      joy      2\n\n[2000 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>emotion</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>im feeling quite sad and sorry for myself but ...</td>\n      <td>sadness</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>i feel like i am still looking at a blank canv...</td>\n      <td>sadness</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>i feel like a faithful servant</td>\n      <td>love</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>i am just feeling cranky and blue</td>\n      <td>anger</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>i can have for a treat or if i am feeling festive</td>\n      <td>joy</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1995</th>\n      <td>im having ssa examination tomorrow in the morn...</td>\n      <td>sadness</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1996</th>\n      <td>i constantly worry about their fight against n...</td>\n      <td>joy</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1997</th>\n      <td>i feel its important to share this info for th...</td>\n      <td>joy</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1998</th>\n      <td>i truly feel that if you are passionate enough...</td>\n      <td>joy</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1999</th>\n      <td>i feel like i just wanna buy any cute make up ...</td>\n      <td>joy</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>2000 rows × 3 columns</p>\n</div>"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"# Set device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T03:47:32.059043Z","iopub.execute_input":"2025-03-14T03:47:32.059324Z","iopub.status.idle":"2025-03-14T03:47:32.147148Z","shell.execute_reply.started":"2025-03-14T03:47:32.059295Z","shell.execute_reply":"2025-03-14T03:47:32.146344Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# Load and preprocess data\n\ntokenizer = tiktoken.get_encoding('gpt2')\n\n# Create datasets with device\ntrain_dataset = TextDataset(train_df, tokenizer, device)\nval_dataset = TextDataset(validation_df, tokenizer, device)\ntest_dataset = TextDataset(test_df, tokenizer, device)","metadata":{"id":"jdZcu7ZKBVBZ","trusted":true,"execution":{"iopub.status.busy":"2025-03-14T03:47:32.147849Z","iopub.execute_input":"2025-03-14T03:47:32.148085Z","iopub.status.idle":"2025-03-14T03:47:33.689753Z","shell.execute_reply.started":"2025-03-14T03:47:32.148063Z","shell.execute_reply":"2025-03-14T03:47:33.689100Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"for input_ids, label in train_dataset:\n    print(input_ids)\n    print(label)\n    break\n\n\n","metadata":{"id":"pryUvgK7ETbY","outputId":"b1a06135-0920-43a7-f8ea-795d841e0f8c","colab":{"base_uri":"https://localhost:8080/"},"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T03:47:33.690467Z","iopub.execute_input":"2025-03-14T03:47:33.690708Z","iopub.status.idle":"2025-03-14T03:47:33.950891Z","shell.execute_reply.started":"2025-03-14T03:47:33.690687Z","shell.execute_reply":"2025-03-14T03:47:33.950131Z"}},"outputs":[{"name":"stdout","text":"tensor([   72, 42547,  1254, 42659], device='cuda:0')\ntensor(4, device='cuda:0')\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"# Create dataloaders\nbatch_size = 32\ntrain_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\nval_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\ntest_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)","metadata":{"id":"yxaHUt79BV5c","trusted":true,"execution":{"iopub.status.busy":"2025-03-14T03:47:33.951638Z","iopub.execute_input":"2025-03-14T03:47:33.951946Z","iopub.status.idle":"2025-03-14T03:47:33.955903Z","shell.execute_reply.started":"2025-03-14T03:47:33.951923Z","shell.execute_reply":"2025-03-14T03:47:33.955169Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# Initialize the Transformer model\nvocab_size = tokenizer.n_vocab\nembed_size = 256\nd_model = 256\nnum_heads = 8\nd_ff = 512\noutput_size = len(train_df['label'].unique())\nnum_layers = 3\ndropout = 0.2\n\n# Initialize model and move to device\nmodel = TransformerModel(vocab_size, embed_size, d_model, num_heads, d_ff, output_size, num_layers, dropout)\nmodel = model.to(device)","metadata":{"id":"wfFQKb4-BX1q","trusted":true,"execution":{"iopub.status.busy":"2025-03-14T04:11:49.265469Z","iopub.execute_input":"2025-03-14T04:11:49.265875Z","iopub.status.idle":"2025-03-14T04:11:49.422789Z","shell.execute_reply.started":"2025-03-14T04:11:49.265837Z","shell.execute_reply":"2025-03-14T04:11:49.421862Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"# Initialize loss and optimizer\ncriterion = nn.CrossEntropyLoss().to(device)\noptimizer = optim.SGD(model.parameters(), lr=0.0001)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T04:11:58.178674Z","iopub.execute_input":"2025-03-14T04:11:58.178955Z","iopub.status.idle":"2025-03-14T04:11:58.183030Z","shell.execute_reply.started":"2025-03-14T04:11:58.178932Z","shell.execute_reply":"2025-03-14T04:11:58.182221Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"for input_ids, labels in val_dataloader:\n    outputs = model(input_ids)\n    print(outputs.size())\n    print(outputs)\n    print()\n    print(torch.max(outputs,1))\n    print()\n    _, predicted = torch.max(outputs,1)\n    print(_)\n    print(predicted)\n    break\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T03:47:36.043222Z","iopub.execute_input":"2025-03-14T03:47:36.043647Z","iopub.status.idle":"2025-03-14T03:47:36.675812Z","shell.execute_reply.started":"2025-03-14T03:47:36.043613Z","shell.execute_reply":"2025-03-14T03:47:36.675119Z"}},"outputs":[{"name":"stdout","text":"torch.Size([32, 6])\ntensor([[-0.9681, -0.0581,  1.0815,  0.3145,  0.9513, -0.4801],\n        [-0.9470,  0.1412,  1.0625,  0.5648,  1.0482, -0.8358],\n        [-0.9632,  0.1790,  0.9773,  0.0340,  1.5458,  0.0882],\n        [-1.5710, -0.2870,  1.2744,  0.6619,  1.0289, -0.8508],\n        [-0.9681, -0.1050,  1.0676,  0.7444,  1.0113, -0.7773],\n        [-0.8513, -0.3751,  0.5126,  0.5425,  1.0086, -0.3616],\n        [-1.0313,  0.2228,  0.7346,  0.5097,  0.5218, -0.3493],\n        [-1.1895,  0.3365,  1.1550,  0.0657,  0.7774, -0.7578],\n        [-1.3988, -0.0792,  0.9848, -0.1299,  1.3961, -0.7063],\n        [-0.8254,  0.0139,  1.1990,  0.4045,  1.0936, -0.3269],\n        [-0.4513, -0.3821,  0.6357,  0.2269,  1.5763, -0.9907],\n        [-1.2924,  0.1783,  0.5985, -0.1882,  0.9726, -0.5302],\n        [-0.9497,  0.0864,  0.4326,  0.2306,  1.2132, -0.8298],\n        [-1.1875, -0.3001,  1.0294,  0.2445,  1.1197, -0.1908],\n        [-0.5547,  0.1921,  0.7546, -0.0142,  1.1118, -0.6957],\n        [-0.2526,  0.2470,  0.2588,  0.2376,  0.9548, -0.5219],\n        [-0.6790, -0.2264,  0.6817,  0.0694,  1.2895, -0.5144],\n        [-1.0442,  0.2009,  1.0178,  0.5113,  0.6101, -0.7973],\n        [-0.0765,  0.1899, -0.1883,  0.1318,  0.8236, -0.7143],\n        [-0.5077, -0.1317,  0.4898,  0.0080,  1.3956, -0.2021],\n        [-1.1926,  0.0152,  0.4182,  0.3150,  1.2699, -1.2637],\n        [-0.5001,  0.1215,  0.7392,  0.4041,  1.0022, -1.1054],\n        [-0.6884,  0.2735,  0.4109, -0.1499,  1.4159, -0.3431],\n        [-0.6471,  0.1300,  0.9980,  0.0415,  1.0391, -0.7551],\n        [-0.6699,  0.2849,  0.2747,  0.0724,  1.1268, -0.4772],\n        [-0.0403,  0.5359,  0.1058, -0.1133,  1.1108, -0.6758],\n        [-0.4264,  0.1939,  0.1783,  0.1046,  0.7243, -0.5179],\n        [-1.2827, -0.1556,  1.2324,  0.3876,  0.7115, -0.8707],\n        [-1.4213,  0.4575,  0.7437, -0.1077,  0.9239, -0.6158],\n        [-0.9040, -0.0391,  0.8304,  0.5534,  0.8349, -1.1758],\n        [-0.8543, -0.1816,  0.4524,  0.1114,  0.9404, -0.9751],\n        [-1.3530,  0.2300,  0.5565,  0.3261,  1.1150, -0.8103]],\n       device='cuda:0', grad_fn=<AddmmBackward0>)\n\ntorch.return_types.max(\nvalues=tensor([1.0815, 1.0625, 1.5458, 1.2744, 1.0676, 1.0086, 0.7346, 1.1550, 1.3961,\n        1.1990, 1.5763, 0.9726, 1.2132, 1.1197, 1.1118, 0.9548, 1.2895, 1.0178,\n        0.8236, 1.3956, 1.2699, 1.0022, 1.4159, 1.0391, 1.1268, 1.1108, 0.7243,\n        1.2324, 0.9239, 0.8349, 0.9404, 1.1150], device='cuda:0',\n       grad_fn=<MaxBackward0>),\nindices=tensor([2, 2, 4, 2, 2, 4, 2, 2, 4, 2, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4,\n        4, 4, 4, 2, 4, 4, 4, 4], device='cuda:0'))\n\ntensor([1.0815, 1.0625, 1.5458, 1.2744, 1.0676, 1.0086, 0.7346, 1.1550, 1.3961,\n        1.1990, 1.5763, 0.9726, 1.2132, 1.1197, 1.1118, 0.9548, 1.2895, 1.0178,\n        0.8236, 1.3956, 1.2699, 1.0022, 1.4159, 1.0391, 1.1268, 1.1108, 0.7243,\n        1.2324, 0.9239, 0.8349, 0.9404, 1.1150], device='cuda:0',\n       grad_fn=<MaxBackward0>)\ntensor([2, 2, 4, 2, 2, 4, 2, 2, 4, 2, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4,\n        4, 4, 4, 2, 4, 4, 4, 4], device='cuda:0')\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"# Define the accuracy function (using the first version from before)\ndef calculate_accuracy(outputs, labels):\n    _, predicted = torch.max(outputs, 1)\n    total = labels.size(0)\n    correct = (predicted == labels).sum().item()\n    accuracy = 100 * correct / total\n    return accuracy, correct, total","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T03:47:36.676572Z","iopub.execute_input":"2025-03-14T03:47:36.676779Z","iopub.status.idle":"2025-03-14T03:47:36.680646Z","shell.execute_reply.started":"2025-03-14T03:47:36.676761Z","shell.execute_reply":"2025-03-14T03:47:36.679982Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"# Training loop with model saving\nbest_val_accuracy = 0.0  # Track the best validation accuracy\nbest_model_path = 'best_model.pth'  # File path to save the best model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T03:47:36.681452Z","iopub.execute_input":"2025-03-14T03:47:36.681754Z","iopub.status.idle":"2025-03-14T03:47:36.694290Z","shell.execute_reply.started":"2025-03-14T03:47:36.681723Z","shell.execute_reply":"2025-03-14T03:47:36.693481Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"num_epochs = 100\n\nfor epoch in range(num_epochs):\n    # Training step\n    model.train()\n    train_correct = 0\n    train_total = 0\n    for input_ids, labels in train_dataloader:\n        optimizer.zero_grad()\n        outputs = model(input_ids)\n        loss = criterion(outputs, labels)\n        \n        # Calculate training accuracy\n        batch_acc, batch_correct, batch_total = calculate_accuracy(outputs, labels)\n        train_correct += batch_correct\n        train_total += batch_total\n        \n        loss.backward()\n        optimizer.step()\n    \n    train_accuracy = 100 * train_correct / train_total\n    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}\")\n    print(f\"Correct/Total: {train_correct}/{train_total}, Training Accuracy after Epoch {epoch+1}: {train_accuracy:.2f}%\")\n\n    # Validation step\n    model.eval()\n    val_correct = 0\n    val_total = 0\n    with torch.no_grad():\n        for input_ids, labels in val_dataloader:\n            outputs = model(input_ids)\n            batch_acc, batch_correct, batch_total = calculate_accuracy(outputs, labels)\n            val_correct += batch_correct\n            val_total += batch_total\n\n    val_accuracy = 100 * val_correct / val_total\n    print(f\"Correct/Total: {val_correct}/{val_total}, Validation Accuracy after Epoch {epoch+1}: {val_accuracy:.2f}%\")\n\n    # Save model if validation accuracy improves\n    if val_accuracy > best_val_accuracy:\n        best_val_accuracy = val_accuracy\n        torch.save(model.state_dict(), best_model_path)\n    \n    print()  # Add a blank line for readability","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":426},"id":"TCDm8oP1BaMl","outputId":"b0540645-1ca9-40d4-df6a-35af6b69c03b","trusted":true,"execution":{"iopub.status.busy":"2025-03-14T04:44:56.098660Z","iopub.execute_input":"2025-03-14T04:44:56.098973Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/100, Loss: 1.8428\nCorrect/Total: 5736/16000, Training Accuracy after Epoch 1: 35.85%\nCorrect/Total: 726/2000, Validation Accuracy after Epoch 1: 36.30%\n\nEpoch 2/100, Loss: 1.6083\nCorrect/Total: 5759/16000, Training Accuracy after Epoch 2: 35.99%\nCorrect/Total: 731/2000, Validation Accuracy after Epoch 2: 36.55%\n\nEpoch 3/100, Loss: 1.4629\nCorrect/Total: 5712/16000, Training Accuracy after Epoch 3: 35.70%\nCorrect/Total: 728/2000, Validation Accuracy after Epoch 3: 36.40%\n\nEpoch 4/100, Loss: 1.4045\nCorrect/Total: 5737/16000, Training Accuracy after Epoch 4: 35.86%\nCorrect/Total: 732/2000, Validation Accuracy after Epoch 4: 36.60%\n\nEpoch 5/100, Loss: 1.6317\nCorrect/Total: 5716/16000, Training Accuracy after Epoch 5: 35.73%\nCorrect/Total: 727/2000, Validation Accuracy after Epoch 5: 36.35%\n\nEpoch 6/100, Loss: 1.5289\nCorrect/Total: 5737/16000, Training Accuracy after Epoch 6: 35.86%\nCorrect/Total: 728/2000, Validation Accuracy after Epoch 6: 36.40%\n\nEpoch 7/100, Loss: 1.6133\nCorrect/Total: 5736/16000, Training Accuracy after Epoch 7: 35.85%\nCorrect/Total: 728/2000, Validation Accuracy after Epoch 7: 36.40%\n\nEpoch 8/100, Loss: 1.2744\nCorrect/Total: 5704/16000, Training Accuracy after Epoch 8: 35.65%\nCorrect/Total: 731/2000, Validation Accuracy after Epoch 8: 36.55%\n\nEpoch 9/100, Loss: 1.5016\nCorrect/Total: 5673/16000, Training Accuracy after Epoch 9: 35.46%\nCorrect/Total: 730/2000, Validation Accuracy after Epoch 9: 36.50%\n\nEpoch 10/100, Loss: 1.8093\nCorrect/Total: 5678/16000, Training Accuracy after Epoch 10: 35.49%\nCorrect/Total: 735/2000, Validation Accuracy after Epoch 10: 36.75%\n\nEpoch 11/100, Loss: 1.4435\nCorrect/Total: 5762/16000, Training Accuracy after Epoch 11: 36.01%\nCorrect/Total: 732/2000, Validation Accuracy after Epoch 11: 36.60%\n\nEpoch 12/100, Loss: 1.4556\nCorrect/Total: 5743/16000, Training Accuracy after Epoch 12: 35.89%\nCorrect/Total: 730/2000, Validation Accuracy after Epoch 12: 36.50%\n\nEpoch 13/100, Loss: 1.5696\nCorrect/Total: 5703/16000, Training Accuracy after Epoch 13: 35.64%\nCorrect/Total: 736/2000, Validation Accuracy after Epoch 13: 36.80%\n\nEpoch 14/100, Loss: 1.5712\nCorrect/Total: 5786/16000, Training Accuracy after Epoch 14: 36.16%\nCorrect/Total: 729/2000, Validation Accuracy after Epoch 14: 36.45%\n\nEpoch 15/100, Loss: 1.3651\nCorrect/Total: 5723/16000, Training Accuracy after Epoch 15: 35.77%\nCorrect/Total: 731/2000, Validation Accuracy after Epoch 15: 36.55%\n\nEpoch 16/100, Loss: 1.7473\nCorrect/Total: 5780/16000, Training Accuracy after Epoch 16: 36.12%\nCorrect/Total: 733/2000, Validation Accuracy after Epoch 16: 36.65%\n\nEpoch 17/100, Loss: 1.4240\nCorrect/Total: 5682/16000, Training Accuracy after Epoch 17: 35.51%\nCorrect/Total: 729/2000, Validation Accuracy after Epoch 17: 36.45%\n\nEpoch 18/100, Loss: 1.6705\nCorrect/Total: 5795/16000, Training Accuracy after Epoch 18: 36.22%\nCorrect/Total: 734/2000, Validation Accuracy after Epoch 18: 36.70%\n\nEpoch 19/100, Loss: 1.5188\nCorrect/Total: 5774/16000, Training Accuracy after Epoch 19: 36.09%\nCorrect/Total: 732/2000, Validation Accuracy after Epoch 19: 36.60%\n\nEpoch 20/100, Loss: 1.4335\nCorrect/Total: 5737/16000, Training Accuracy after Epoch 20: 35.86%\nCorrect/Total: 729/2000, Validation Accuracy after Epoch 20: 36.45%\n\nEpoch 21/100, Loss: 1.6814\nCorrect/Total: 5785/16000, Training Accuracy after Epoch 21: 36.16%\nCorrect/Total: 729/2000, Validation Accuracy after Epoch 21: 36.45%\n\nEpoch 22/100, Loss: 1.3681\nCorrect/Total: 5791/16000, Training Accuracy after Epoch 22: 36.19%\nCorrect/Total: 734/2000, Validation Accuracy after Epoch 22: 36.70%\n\nEpoch 23/100, Loss: 1.5251\nCorrect/Total: 5787/16000, Training Accuracy after Epoch 23: 36.17%\nCorrect/Total: 739/2000, Validation Accuracy after Epoch 23: 36.95%\n\nEpoch 24/100, Loss: 1.3691\nCorrect/Total: 5745/16000, Training Accuracy after Epoch 24: 35.91%\nCorrect/Total: 731/2000, Validation Accuracy after Epoch 24: 36.55%\n\nEpoch 25/100, Loss: 1.6153\nCorrect/Total: 5781/16000, Training Accuracy after Epoch 25: 36.13%\nCorrect/Total: 736/2000, Validation Accuracy after Epoch 25: 36.80%\n\nEpoch 26/100, Loss: 1.4502\nCorrect/Total: 5794/16000, Training Accuracy after Epoch 26: 36.21%\nCorrect/Total: 734/2000, Validation Accuracy after Epoch 26: 36.70%\n\nEpoch 27/100, Loss: 1.4266\nCorrect/Total: 5802/16000, Training Accuracy after Epoch 27: 36.26%\nCorrect/Total: 732/2000, Validation Accuracy after Epoch 27: 36.60%\n\nEpoch 28/100, Loss: 1.5363\nCorrect/Total: 5793/16000, Training Accuracy after Epoch 28: 36.21%\nCorrect/Total: 733/2000, Validation Accuracy after Epoch 28: 36.65%\n\nEpoch 29/100, Loss: 1.6036\nCorrect/Total: 5757/16000, Training Accuracy after Epoch 29: 35.98%\nCorrect/Total: 737/2000, Validation Accuracy after Epoch 29: 36.85%\n\nEpoch 30/100, Loss: 1.6668\nCorrect/Total: 5750/16000, Training Accuracy after Epoch 30: 35.94%\nCorrect/Total: 735/2000, Validation Accuracy after Epoch 30: 36.75%\n\nEpoch 31/100, Loss: 1.3783\nCorrect/Total: 5793/16000, Training Accuracy after Epoch 31: 36.21%\nCorrect/Total: 737/2000, Validation Accuracy after Epoch 31: 36.85%\n\nEpoch 32/100, Loss: 1.6037\nCorrect/Total: 5818/16000, Training Accuracy after Epoch 32: 36.36%\nCorrect/Total: 734/2000, Validation Accuracy after Epoch 32: 36.70%\n\nEpoch 33/100, Loss: 1.6595\nCorrect/Total: 5809/16000, Training Accuracy after Epoch 33: 36.31%\nCorrect/Total: 730/2000, Validation Accuracy after Epoch 33: 36.50%\n\nEpoch 34/100, Loss: 1.4361\nCorrect/Total: 5759/16000, Training Accuracy after Epoch 34: 35.99%\nCorrect/Total: 732/2000, Validation Accuracy after Epoch 34: 36.60%\n\nEpoch 35/100, Loss: 1.4553\nCorrect/Total: 5777/16000, Training Accuracy after Epoch 35: 36.11%\nCorrect/Total: 732/2000, Validation Accuracy after Epoch 35: 36.60%\n\nEpoch 36/100, Loss: 1.5107\nCorrect/Total: 5814/16000, Training Accuracy after Epoch 36: 36.34%\nCorrect/Total: 729/2000, Validation Accuracy after Epoch 36: 36.45%\n\nEpoch 37/100, Loss: 1.5325\nCorrect/Total: 5771/16000, Training Accuracy after Epoch 37: 36.07%\nCorrect/Total: 734/2000, Validation Accuracy after Epoch 37: 36.70%\n\nEpoch 38/100, Loss: 1.5098\nCorrect/Total: 5865/16000, Training Accuracy after Epoch 38: 36.66%\nCorrect/Total: 733/2000, Validation Accuracy after Epoch 38: 36.65%\n\nEpoch 39/100, Loss: 1.5197\nCorrect/Total: 5843/16000, Training Accuracy after Epoch 39: 36.52%\nCorrect/Total: 730/2000, Validation Accuracy after Epoch 39: 36.50%\n\nEpoch 40/100, Loss: 1.5489\nCorrect/Total: 5850/16000, Training Accuracy after Epoch 40: 36.56%\nCorrect/Total: 734/2000, Validation Accuracy after Epoch 40: 36.70%\n\nEpoch 41/100, Loss: 1.4205\nCorrect/Total: 5845/16000, Training Accuracy after Epoch 41: 36.53%\nCorrect/Total: 731/2000, Validation Accuracy after Epoch 41: 36.55%\n\nEpoch 42/100, Loss: 1.7411\nCorrect/Total: 5830/16000, Training Accuracy after Epoch 42: 36.44%\nCorrect/Total: 733/2000, Validation Accuracy after Epoch 42: 36.65%\n\nEpoch 43/100, Loss: 1.5450\nCorrect/Total: 5831/16000, Training Accuracy after Epoch 43: 36.44%\nCorrect/Total: 734/2000, Validation Accuracy after Epoch 43: 36.70%\n\nEpoch 44/100, Loss: 1.5986\nCorrect/Total: 5797/16000, Training Accuracy after Epoch 44: 36.23%\nCorrect/Total: 733/2000, Validation Accuracy after Epoch 44: 36.65%\n\nEpoch 45/100, Loss: 1.6489\nCorrect/Total: 5802/16000, Training Accuracy after Epoch 45: 36.26%\nCorrect/Total: 732/2000, Validation Accuracy after Epoch 45: 36.60%\n\nEpoch 46/100, Loss: 1.5230\nCorrect/Total: 5836/16000, Training Accuracy after Epoch 46: 36.48%\nCorrect/Total: 732/2000, Validation Accuracy after Epoch 46: 36.60%\n\nEpoch 47/100, Loss: 1.4537\nCorrect/Total: 5848/16000, Training Accuracy after Epoch 47: 36.55%\nCorrect/Total: 733/2000, Validation Accuracy after Epoch 47: 36.65%\n\nEpoch 48/100, Loss: 1.6816\nCorrect/Total: 5916/16000, Training Accuracy after Epoch 48: 36.98%\nCorrect/Total: 739/2000, Validation Accuracy after Epoch 48: 36.95%\n\nEpoch 49/100, Loss: 1.6343\nCorrect/Total: 5871/16000, Training Accuracy after Epoch 49: 36.69%\nCorrect/Total: 733/2000, Validation Accuracy after Epoch 49: 36.65%\n\nEpoch 50/100, Loss: 1.4012\nCorrect/Total: 5820/16000, Training Accuracy after Epoch 50: 36.38%\nCorrect/Total: 738/2000, Validation Accuracy after Epoch 50: 36.90%\n\nEpoch 51/100, Loss: 1.5876\nCorrect/Total: 5808/16000, Training Accuracy after Epoch 51: 36.30%\nCorrect/Total: 736/2000, Validation Accuracy after Epoch 51: 36.80%\n\nEpoch 52/100, Loss: 1.4154\nCorrect/Total: 5865/16000, Training Accuracy after Epoch 52: 36.66%\nCorrect/Total: 742/2000, Validation Accuracy after Epoch 52: 37.10%\n\nEpoch 53/100, Loss: 1.6796\nCorrect/Total: 5858/16000, Training Accuracy after Epoch 53: 36.61%\nCorrect/Total: 733/2000, Validation Accuracy after Epoch 53: 36.65%\n\nEpoch 54/100, Loss: 1.6078\nCorrect/Total: 5770/16000, Training Accuracy after Epoch 54: 36.06%\nCorrect/Total: 738/2000, Validation Accuracy after Epoch 54: 36.90%\n\nEpoch 55/100, Loss: 1.6621\nCorrect/Total: 5812/16000, Training Accuracy after Epoch 55: 36.33%\nCorrect/Total: 736/2000, Validation Accuracy after Epoch 55: 36.80%\n\nEpoch 56/100, Loss: 1.6736\nCorrect/Total: 5914/16000, Training Accuracy after Epoch 56: 36.96%\nCorrect/Total: 738/2000, Validation Accuracy after Epoch 56: 36.90%\n\nEpoch 57/100, Loss: 1.4687\nCorrect/Total: 5928/16000, Training Accuracy after Epoch 57: 37.05%\nCorrect/Total: 738/2000, Validation Accuracy after Epoch 57: 36.90%\n\nEpoch 58/100, Loss: 1.5860\nCorrect/Total: 5852/16000, Training Accuracy after Epoch 58: 36.58%\nCorrect/Total: 734/2000, Validation Accuracy after Epoch 58: 36.70%\n\nEpoch 59/100, Loss: 1.6393\nCorrect/Total: 5906/16000, Training Accuracy after Epoch 59: 36.91%\nCorrect/Total: 738/2000, Validation Accuracy after Epoch 59: 36.90%\n\nEpoch 60/100, Loss: 1.4013\nCorrect/Total: 5829/16000, Training Accuracy after Epoch 60: 36.43%\nCorrect/Total: 737/2000, Validation Accuracy after Epoch 60: 36.85%\n\nEpoch 61/100, Loss: 1.6501\nCorrect/Total: 5896/16000, Training Accuracy after Epoch 61: 36.85%\nCorrect/Total: 740/2000, Validation Accuracy after Epoch 61: 37.00%\n\nEpoch 62/100, Loss: 1.5831\nCorrect/Total: 5839/16000, Training Accuracy after Epoch 62: 36.49%\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# Assuming the same model architecture\nmodel.load_state_dict(torch.load('best_model.pth'))\nmodel.eval()  # Set to evaluation mode if using for inference","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T03:59:21.390365Z","iopub.execute_input":"2025-03-14T03:59:21.390633Z","iopub.status.idle":"2025-03-14T03:59:21.458270Z","shell.execute_reply.started":"2025-03-14T03:59:21.390610Z","shell.execute_reply":"2025-03-14T03:59:21.457447Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-28-91a431c573e8>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load('best_model.pth'))\n","output_type":"stream"},{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"TransformerModel(\n  (embedding): Embedding(50257, 256)\n  (positional_encoding): PositionalEncoding()\n  (encoder_layers): ModuleList(\n    (0-1): 2 x TransformerEncoderLayer(\n      (wq): Linear(in_features=256, out_features=256, bias=True)\n      (wk): Linear(in_features=256, out_features=256, bias=True)\n      (wv): Linear(in_features=256, out_features=256, bias=True)\n      (dense): Linear(in_features=256, out_features=256, bias=True)\n      (feed_forward): Sequential(\n        (0): Linear(in_features=256, out_features=512, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=512, out_features=256, bias=True)\n      )\n      (layernorm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n      (layernorm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.3, inplace=False)\n    )\n  )\n  (fc): Linear(in_features=256, out_features=6, bias=True)\n  (dropout): Dropout(p=0.3, inplace=False)\n)"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"test_correct, test_total = 0, 0\n\nfor input_ids, labels in test_dataloader:\n    outputs = model(input_ids)\n    batch_acc, batch_correct, batch_total = calculate_accuracy(outputs, labels)\n    test_correct += batch_correct\n    test_total += batch_total\n\ntest_accuracy = 100 * test_correct / test_total\nprint(f\"Correct/Total: {test_correct}/{test_total}, Accuracy: {test_accuracy:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T03:59:21.459119Z","iopub.execute_input":"2025-03-14T03:59:21.459439Z","iopub.status.idle":"2025-03-14T03:59:21.772875Z","shell.execute_reply.started":"2025-03-14T03:59:21.459410Z","shell.execute_reply":"2025-03-14T03:59:21.772231Z"}},"outputs":[{"name":"stdout","text":"Correct/Total: 1745/2000, Accuracy: 87.25%\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"def predict_emotion(sentence, model, tokenizer, device):\n    # Preprocess the input sentence\n    sentence = sentence.lower()\n    encoding = tokenizer.encode(sentence)\n    input_ids = torch.tensor(encoding, dtype=torch.long, device=device).unsqueeze(0)\n    \n    # Make prediction\n    model.eval()\n    with torch.no_grad():\n        outputs = model(input_ids)\n        accuracy, predicted = torch.max(outputs, 1)\n          \n    return label_dict[predicted.item()]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T03:59:21.773562Z","iopub.execute_input":"2025-03-14T03:59:21.773761Z","iopub.status.idle":"2025-03-14T03:59:21.778051Z","shell.execute_reply.started":"2025-03-14T03:59:21.773744Z","shell.execute_reply":"2025-03-14T03:59:21.777290Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"# Example usage\ntest_sentence = input()\npredicted_emotion = predict_emotion(test_sentence, model, tokenizer, device)\nprint(f\"Sentence: {test_sentence}\")\nprint(f\"Predicted emotion: {predicted_emotion}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T03:59:21.778835Z","iopub.execute_input":"2025-03-14T03:59:21.779113Z","iopub.status.idle":"2025-03-14T03:59:26.355210Z","shell.execute_reply.started":"2025-03-14T03:59:21.779082Z","shell.execute_reply":"2025-03-14T03:59:26.354292Z"}},"outputs":[{"output_type":"stream","name":"stdin","text":" àd\n"},{"name":"stdout","text":"Sentence: àd\nPredicted emotion: joy\n","output_type":"stream"}],"execution_count":31}]}